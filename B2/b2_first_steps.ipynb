{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing a tiny supervised learning flow (B2 level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am following the first supervised learning steps from the \"Machine Learning 1\" notes. My goal is to keep the code ",
    "simple and to explain every move like a beginner who is still connecting the dots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will:\n",
    "1. Write down a very small Iris style data set by hand.\n",
    "2. Explore basic statistics to imitate the descriptive analysis suggested in the theory.\n",
    "3. Split the data into train and test parts so I can evaluate honestly.\n",
    "4. Build a tiny k-nearest neighbors (k-NN) classifier from scratch using only Python basics.\n",
    "5. Measure the accuracy and try a manual prediction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a friendly mini data set\n",
    "The notes talk about the Iris flowers, so I copy twelve rows (four features + species).\n",
    "Having the values here keeps the project self contained and avoids extra installations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "iris_rows = [\n    \"5.1,3.5,1.4,0.2,setosa\",\n    \"4.9,3.0,1.4,0.2,setosa\",\n    \"5.0,3.6,1.4,0.3,setosa\",\n    \"5.4,3.9,1.7,0.4,setosa\",\n    \"5.8,2.7,4.1,1.0,versicolor\",\n    \"6.0,2.2,4.0,1.0,versicolor\",\n    \"6.4,3.2,4.5,1.5,versicolor\",\n    \"6.6,2.9,4.6,1.3,versicolor\",\n    \"6.3,3.3,6.0,2.5,virginica\",\n    \"5.8,2.7,5.1,1.9,virginica\",\n    \"7.1,3.0,5.9,2.1,virginica\",\n    \"6.5,3.0,5.2,2.0,virginica\"\n]\nprint(f\"Loaded {len(iris_rows)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the rows into numbers and labels\n",
    "The theory says we work with feature vectors and targets.\n",
    "I convert each line into a tuple: ([features], label)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_rows(rows):\n    dataset = []\n    for row in rows:\n        parts = row.split(\",\")\n        features = [float(value) for value in parts[:4]]\n        label = parts[4]\n        dataset.append((features, label))\n    return dataset\n\nfull_dataset = parse_rows(iris_rows)\nprint(full_dataset[0])\nprint(f\"Total samples: {len(full_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the basic statistics\n",
    "To keep it simple I calculate minimum, maximum, and average for each feature.\n",
    "This mimics the descriptive analysis chapter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_names = [\n    \"sepal length (cm)\",\n    \"sepal width (cm)\",\n    \"petal length (cm)\",\n    \"petal width (cm)\"\n]\n\ndef describe_feature(dataset, index):\n    values = [row[0][index] for row in dataset]\n    minimum = min(values)\n    maximum = max(values)\n    average = sum(values) / len(values)\n    return minimum, maximum, average\n\nfor idx, name in enumerate(feature_names):\n    min_val, max_val, avg_val = describe_feature(full_dataset, idx)\n    print(f\"{name}: min={min_val:.1f}, max={max_val:.1f}, avg={avg_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "I shuffle the data with a fixed seed (so results are repeatable) and keep 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_test_split(dataset, test_ratio=0.25, seed=42):\n    random.seed(seed)\n    shuffled = dataset[:]\n    random.shuffle(shuffled)\n    test_size = max(1, int(len(shuffled) * test_ratio))\n    test_data = shuffled[:test_size]\n    train_data = shuffled[test_size:]\n    return train_data, test_data\n\ntrain_data, test_data = train_test_split(full_dataset)\nprint(f\"Train size: {len(train_data)}\")\nprint(f\"Test size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a pocket k-NN classifier\n",
    "The theory explains that k-NN looks at the closest examples.\n",
    "I use the Euclidean distance and keep k = 3 neighbors because it is a small data set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n    total = 0.0\n    for value_a, value_b in zip(a, b):\n        total += (value_a - value_b) ** 2\n    return total ** 0.5\n\n\ndef knn_predict(train_set, new_sample, k=3):\n    distances = []\n    for features, label in train_set:\n        distance = euclidean_distance(features, new_sample)\n        distances.append((distance, label))\n    distances.sort(key=lambda item: item[0])\n    neighbors = distances[:k]\n    votes = {}\n    for _, neighbor_label in neighbors:\n        votes[neighbor_label] = votes.get(neighbor_label, 0) + 1\n    best_label = max(votes.items(), key=lambda item: item[1])[0]\n    return best_label\n\nprint(knn_predict(train_data, test_data[0][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating accuracy\n",
    "I check how many test samples the classifier gets right and compute the proportion."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy_score(model_data, test_set, k=3):\n    correct = 0\n    for features, expected_label in test_set:\n        predicted_label = knn_predict(model_data, features, k=k)\n        if predicted_label == expected_label:\n            correct += 1\n    return correct / len(test_set)\n\naccuracy = accuracy_score(train_data, test_data)\nprint(f\"Accuracy on the test set: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying a manual prediction\n",
    "To see the algorithm in action I pick a flower with long petals and check the predicted species."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "mystery_flower = [6.1, 2.8, 4.7, 1.4]\nprediction = knn_predict(train_data, mystery_flower)\nprint(f\"Predicted species: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small conclusions\n",
    "- Preparing the data by hand helped me understand every column.\n",
    "- The evaluation step shows if my simple intuition is on the right track.\n",
    "- With more data I could tune *k* or try other algorithms from the course notes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}